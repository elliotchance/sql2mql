# Token
# =====

# A **Token** represents a single token read from the stream.
class Token

	# The name of the token, eg. 'INTEGER'
	token = null
	
	# The value captured for this token, this is to hold the value captured by the regular
	# expression like '123'
	value = null
	
	# Blank constructor
	constructor: (@token, @value = null) ->
	
	# The string representation is just the _value_ captured.
	toString: () ->
		return @value

# RightOperand
# ============

# A **BinaryExpression** is read as the syntax:
#
#     LeftExpression [Operator RightExpression]...
#
# The **RightOperand** represents the _Operator_ and _RightExpression_
class RightOperand

	# _Operator_
	operator = null
	
	# _RightExpression_
	right = null
	
	# Blank constructor.
	constructor: (@operator, @right) ->
	
	# Convert **RightOperand** to a string.
	toString: () ->
		return @operator.toString() + " " + @right.toString()

# MqlOptimizer
# ============

# This class handles cases when the BSON can be reduced to a more simple form.
class MqlOptimizer

	# Return the keys of an array.
	getArrayKeys: (obj) ->
		keys = []
		for k, v of obj
			keys.push(k)
		return keys

	# Take in BSON and recurse through it to find ways to make it simpler.
	optimizeBson: (bson) ->
		# Return anything that is not an object unharmed.
		if typeof bson != 'object'
			return bson
		
		# Iterate through the root keys of the BSON.
		out = {}
		for k, v of bson
			if k == '$and'
				# Check if all the keys relate to the same field?
				field = @getArrayKeys(v[0])
				for k2, v2 of v
					if field.toString() != @getArrayKeys(v2)[0].toString()
						field = null
						break
				
				# If field still retains a value then all the keys are the same and we can simplify
				# this expression...
				if field
					out[field] = {}
					for k2, v2 of v
						op = @getArrayKeys(v2[field])[0]
						out[field][op] = v2[field][op]
				# ... No such luck.
				else
					out['$and'] = v
			# There is nothing we can do, so just pass it through.
			else
				out[k] = v
				
		# Simplify single AND
		if @getArrayKeys(out).length == 1 and out['$and']
			removeAnd = true
			for k, v of out['$and']
				if typeof v != 'object'
					removeAnd = false
					break
			if removeAnd
				newOut = {}
				for k, v of out['$and']
					key = @getArrayKeys(v)[0]
					newOut[key] = v[key]
				out = newOut
		
		# All done.
		return out

# MqlTranslator
# =============

# Convert the tree generated by the **MqlLexer** and **MqlParser** into the actual BSON used by
# MongoDB according to the rules for each operator type.
class MqlTranslator
	
	# Given a single operator token name, return the equivilent MongoDB name. This function will
	# return a value or it will throw an Error.
	convertOperator: (op) ->
		switch op
			when '>' then '$gt'
			when '<' then '$lt'
			when '>=' then '$gte'
			when '<=' then '$lte'
			when '=' then '$eq'
			when '!=' then '$ne'
			when 'AND' then '$and'
			when 'OR' then '$or'
			else throw new Error("Unknown operator '" + op + "'")
	
	# Attempt to convert a SQL regular expression like (pun intended) '%Bob%' to a JavaScript
	# regular expression for the BSON value. This function will need more work with anything but
	# simple regular expressions.
	createRegexFromLike: (str) ->
		# Strip quotes.
		str = str.substr(1, str.length - 2)
		
		# Test for start and end anchors.
		if str.charAt(0) != '%'
			str = '^' + str
		if str.charAt(str.length - 1) != '%'
			str = str + '$'
		
		# Handle '%'
		str = str.replace(/%/g, '')
		
		# Enclose the result in forward slashes.
		return '/' + str + '/'
	
	# The primary method to convert a parsed tree into BSON.
	#
	# _fmt_ Can be one of 'object' (default) or 'string'. This is explained in more detail further
	# down.
	#
	# _mode_ The default _mode_ mode is 'where' which treats the _tree_ normally. Other options are
	# 'set' which is explained further down.
	translateMql: (tree, fmt = 'object', mode = 'where') ->
		# It's easier to store the result in this variable while its manipulated and return the
		# result at the very end of the method.
		final = null
		
		# If the _mode_ is 'set' then this function works with the understanding that this tree
		# represents one of the SET expressions from an UPDATE statement - which follows different
		# requirements for the resulting BSON.
		if mode == 'set'
			final = { $set: {} }
			for k, v of tree
				if v.value.operatorClass == 'MANUAL'
					final = v.value.left
				else
					final['$set'][v.field] = @translateMql(v.value)
		
		# The _mode_ is 'where'
		else
			switch tree.operatorClass
				# A **SINGLE** class means there is only one operand, this might be like an
				# **INTEGER** token.
				when 'SINGLE'
					final = @translateMql(tree.left)
				
				# A **LOGICAL** class is the basic construct for things like 'AND', 'OR', etc. But
				# it does not require more than one operand to exist.
				when 'LOGICAL'
					if tree.rights.length == 0
						final = @translateMql(tree.left)
					else
						op = @convertOperator(tree.rights[0].operator.token)
						r = {}
						r[op] = [ @translateMql(tree.left) ]
						for k, v of tree.rights
							r[op].push(@translateMql(v.right))
						final = r
				
				# Handle comparison operators, '>', '!=', 'LIKE' etc. This also does not guarentee
				# more than one operand.
				when 'COMPARISON'
					if tree.rights.length == 0
						final = @translateMql(tree.left)
					else
						r = {}
						
						# There are some a special cases where the token may be handled differently.
						switch tree.rights[0].operator.token
							# BSON does not need a special constructor for equals since it uses
							# {"a":33} to represent "a=33"
							when '='
								r[@translateMql(tree.left)] = @translateMql(tree.rights[0].right)
							
							# **LIKE** operator needs to be aware that it is translating the SQL
							# regular expression into a regex JavaScript can handle.
							when 'LIKE'
								regex = @createRegexFromLike(@translateMql(tree.rights[0].right))
								r[@translateMql(tree.left)] = regex
							
							# Treat anything else as a generic operator.
							else
								op = @convertOperator(tree.rights[0].operator.token)
								
								r[@translateMql(tree.left)] = {}
								r[@translateMql(tree.left)][op] = @translateMql(tree.rights[0].right)

						final = r
				
				# A **TOKEN** is much like a **SINGLE** but it is not wrapped in an **Expression**
				# object.
				when 'TOKEN'
					# try and autocast
					if tree.left.value.match(/^[0-9]+$/)
						final = tree.left.value * 1
					else
						final = tree.left.value
				
				# Uh-oh... we don't know how to handle this... throw an Error.
				else
					throw new Error("Unknown operatorClass '" + tree.operatorClass + "'")
				
			# Before we finish up we run the raw BSON through the optimizer to see if it can be
			# simplified.
			optimizer = new MqlOptimizer()
			final = optimizer.optimizeBson(final)
				
		# If the format is 'object' we just return the object we've created.
		if fmt == 'object'
			return final
			
		# If the format is 'string' we pretty-reduce it.
		if fmt == 'string'
			return @prettyReduce(final)
		
		# We have been provided some invalid format, chuck an Error.
		throw new Error("Unknown format '" + fmt + "'")
	
	# Pretty reducing recognises associative arrays that have all integer indices. This is important
	# because it means {"0":"a","1":"b"} should actually be rendered as ["a","b"].
	prettyReduce: (tree) ->
		# Before we transverse, check to see if all the keys are integers.
		isArray = true		
		for k, v of tree
			if not k.match(/^[0-9]+$/)
				isArray = false
				break
		
		# If it is a true array, build it without indices.
		if isArray
			r = '['
			for k, v of tree
				r += "," if r.length > 1
					
				if typeof v == 'object'
					r += @prettyReduce(v)
				else
					r += v
			r += ']'
		
		# One or more (not zero) of the array keys was not an integer. Render like a normal object.
		else
			r = '{'
			for k, v of tree
				r += "," if r.length > 1
				k = '"' + k + '"' if k.charAt(0) != '$'
					
				if typeof v == 'object'
					r += k + ":" + @prettyReduce(v)
				else
					r += k + ':' + v
			r += '}'
		
		# Return whatever we've built.
		return r

# BinaryExpression
# ================

# A **BinaryExpression** is read as the syntax:
#
#     LeftExpression [Operator RightExpression]...
#
# The combination of "Operator RightExpression" is stored in a single **RightOperand** object.
# These are collectivly called "rights" where there may be zero or more in a given expression.
class BinaryExpression
	
	# Blank constructor. The _operatorClass_ is used to instruct **MqlTranslator** how to handle
	# this type of expression.
	constructor: (@operatorClass, @left, @rights = []) ->
	
	# Push a _right_ onto the stack. A **RightOperand** object will be generated for you with the
	# arguments provided.
	addRight: (operator, right) ->
		rightOperand = new RightOperand(operator, right)
		@rights.push(rightOperand)
		return rightOperand
	
	# The string representation of this expression should return how the expression was seen by the
	# parser with parentheses showing order of operation.
	toString: () ->
		r = ''
		r += '(' if @rights.length > 0
		r += @left.toString()
		for key, value of @rights
			r += " " + value.toString()
		r += ')' if @rights.length > 0
		return r
		
class Expression extends BinaryExpression
	
	constructor: (@left, @rights = []) ->
		super("SINGLE", @left, @rights)
		
class AndExpression extends BinaryExpression
	
	constructor: (@left, @rights = []) ->
		super("LOGICAL", @left, @rights)
		
class AddExpression extends BinaryExpression
	
	constructor: (@left, @rights = []) ->
		super("LOGICAL", @left, @rights)
		
class OrExpression extends BinaryExpression
	
	constructor: (@left, @rights = []) ->
		super("LOGICAL", @left, @rights)
		
class ComparisonExpression extends BinaryExpression
	
	constructor: (@left, @rights = []) ->
		super("COMPARISON", @left, @rights)
		
class SingleExpression extends BinaryExpression
	
	constructor: (@left, @rights = []) ->
		super("TOKEN", @left, @rights)

# Lexer
# =====

# This is a generic lexer for pulling tokens out of a stream. Lexing qualities specific to MongoDB
# are put into the extended class **MqlLexer**. This lexer is destructive in that once a token is
# read from the front of the stream it is cropped off, so the string being tokenized is reduced in
# size with each token that's read.
class Lexer

	# Setup the lexer with the string it is going to tokenize.
	constructor: (@stream = '') ->
		# nothing to do here
	
	# This will first attempt to find the token in _IGNORES_, if so it is forgotten. Otherwise it
	# will attempt to match a token in the order they appear in TOKENS. If a token can not be
	# matched then null is returned.
	nextToken: (peek = false) ->
		# Hit EOF?
		if @stream.length == 0
			return new Token('<EOF>')
	
		# Consume all ignores first (there may be more than one)
		while true
			foundMatch = false
			for tokenName, tokenRegex of @IGNORES
				regex = new RegExp('^' + tokenRegex)
				firstMatch = regex.exec(@stream)
				break if not firstMatch
					
				# Crop this token off the front
				@stream = @stream.substr(firstMatch[0].length)
				foundMatch = true
			
			# No more ignores, the real token comes next.
			break if not foundMatch
		
		# Consume the real token
		for tokenName, tokenRegex of @TOKENS
			regex = new RegExp('^' + tokenRegex)
			firstMatch = regex.exec(@stream)
			if firstMatch
				# Only crop if we are not peeking
				if not peek
					@stream = @stream.substr(firstMatch[0].length)
				return new Token(tokenName, firstMatch[0])
		
		# Return the **Token**.
		return new Token(token, value)
	
	# Peeking returns the next token without cropping it off the front, peeking more than once will
	# always return you the same token.
	peekNextToken: () ->
		return @nextToken(true)

# MqlLexer
# ========

# Use the functionality from **Lexer** with the lexical tokens for SQL.
class MqlLexer extends Lexer

	# Any time we encounter these tokens we can consume and ignore.
	IGNORES:
		# whitespace
		'WHITESPACE': "\\s+"

	# Tokens we may encounter, highest importance first.
	TOKENS:
		# symbols
		'>=': ">="
		'<=': "<="
		'!=': "!="
		
		'*': "\\*"
		',': ","
		'=': "="
		'>': ">"
		'<': "<"
		'+': "\\+"
		
		# keywords
		'AND': "AND"
		'ASC': "ASC"
		'BY': "BY"
		'CREATE': "CREATE"
		'DELETE': "DELETE"
		'DESC': "DESC"
		'FROM': "FROM"
		'LIKE': "LIKE"
		'LIMIT': "LIMIT"
		'ORDER': "ORDER"
		'OR': "OR"
		'SELECT': "SELECT"
		'SET': "SET"
		'SKIP': "SKIP"
		'TABLE': "TABLE"
		'WHERE': "WHERE"
		'UPDATE': "UPDATE"
		
		# SINGLES
		'IDENTIFIER': "[a-zA-Z]+"
		'INTEGER': '[0-9]+'
		'STRING_SINGLE': "'.*'"
		'STRING_DOUBLE': '".*"'
	
	# Initialise parent.
	constructor: (@stream) ->
		super(@stream)

# Parser
# ======

# Generic parser. This is extended by **MqlParser**.
class Parser
	
	# Blank constructor.
	constructor: (@lexer) ->
	
	# Branch decision. Run a function based on the next token. If the next token is not one of the
	# options then an Error is thrown.
	branch: (paths) ->
		# Peek one token.
		next = @lexer.peekNextToken()
		
		# If the token is not understood, stop here.
		if not next.token
			throw new Error("Can not understand '" + next.value + "'")
			
		# The token we consume must be one of the paths provided. If it is run the associated
		# function.
		for tokenName, tokenPath of paths
			if next.token == tokenName
				return tokenPath()
		
		# The token was not one of the possible branches.
		msg = "Found " + next.token + " '" + next.value + "' but expected one of:"
		for k, v of paths
			msg += " " + k
		throw new Error(msg)
	
	# Consume the next **Token** in the stream.
	consume: (token, success) ->
		# Peek the next token and see if it is what we are looking for.
		next = @lexer.nextToken(true)
		if next.token == token
			return success(next.token)
		
		# Otherwise, we have a problem.
		throw new Error("Found " + next.token + " '" + next.value + "' but expected " + token)
	
	# Consume the next token and validate that it is a specific type. If it's not the token we are
	# expecting then an Error is thrown.
	assertNextToken: (wantedToken) ->
		next = @lexer.nextToken()
		@assertToken(wantedToken, next.token)
		return next
	
	# Compare two **Token** types. An Error is thrown if they do not match.
	assertToken: (expectedToken, actualToken) ->
		if actualToken != expectedToken
			throw new Error("Token assertion failed: Expected " + expectedToken + " but actual " +
				"token is " + actualToken)
		return actualToken
	
	# Read the next token from the **Lexer** with the option to just peek the next **Token**.
	nextToken: (peek = false) ->
		return @lexer.nextToken(peek)
	
	# The same thing as nextToken() but only in peek mode.
	peekNextToken: () ->
		return @lexer.peekNextToken()

# OrderByField
# ============

# Hold the description of an ORDER BY field.
class OrderByField

	# Default constructor.
	constructor: (@field, @order = 'ASC') ->
	
	# Render the original SQL.
	toString: () ->
		@field + " " + @order

# MqlParser
# =========

# SQL Parser.
class MqlParser extends Parser

	# The entry point.
	consumeSql: () ->
		r = @branch({
			'SELECT': () => @consumeSelect(),
			'DELETE': () => @consumeDelete(),
			'UPDATE': () => @consumeUpdate(),
			'CREATE': () => @consumeCreate()
		})
		
		return r

	# Consume a CREATE TABLE statement.
	consumeCreate: () ->
		r = {}
		
		# Consume 'CREATE TABLE' tokens.
		r.token = 'CREATE TABLE'
		@assertNextToken('CREATE')
		@assertNextToken('TABLE')
		
		# Table/collection name.
		r.tableName = @assertNextToken('IDENTIFIER').value
		
		# Totally ignore the rest and return what we have.
		return r

	# Consume UPDATE statement.
	consumeUpdate: () ->
		r = {}
		
		# Consume 'UPDATE' token.
		r.token = @assertNextToken('UPDATE').value
		
		# Table/collection name.
		r.from = @assertNextToken('IDENTIFIER').value
		
		# SET is required.
		r.set = @consumeSet()
		
		# WHERE is optional.
		r.where = @consumeWhere() if @peekNextToken().token == 'WHERE'
		
		# All done.
		return r

	# Consume DELETE statement.
	consumeDelete: () ->
		r = {}
		
		# Consume 'DELETE FROM' tokens.
		r.token = @assertNextToken('DELETE').value
		@assertNextToken('FROM')
		
		# Table/collection name.
		r.from = @assertNextToken('IDENTIFIER').value
		
		# WHERE is optional.
		r.where = @consumeWhere() if @peekNextToken().token == 'WHERE'
		
		# All done.
		return r
	
	# Consume the SET clause of an UPDATE statement.
	consumeSet: () ->
		# Consume 'SET' token.
		@assertNextToken('SET')
		
		# Consume columns to be updated.
		return @consumeSetList()
	
	# This needs to be improved to consume more than one column update.
	consumeSetList: () ->
		return [ @consumeSetField() ]
	
	# Consume a single field in a 'UPDATE ... SET ...' statement.
	consumeSetField: () ->
		r = {}
	
		# Field name.
		r.field = @assertNextToken('IDENTIFIER').value
		@assertNextToken('=')
		
		# A constant like an INTEGER.
		if @consumeSingle(true) and @consumeSingle(true).left.token != 'IDENTIFIER'
			r.value = @consumeSingle()
			
		# Recognise self modification (like increment)
		else if @peekNextToken('IDENTIFIER').value == r.field
			@assertNextToken('IDENTIFIER')
			@assertNextToken('+')
			
			manual = {'$inc': {}}
			manual['$inc'][r.field] = @consumeSingle().left.value
			r.value = new BinaryExpression('MANUAL', manual)
		
		# SET has some specific requirements, we didn't fulfil any of them so throw an Error.
		else
			throw new Error("Can't understand UPDATE SET.")
		
		# Success.
		return r

	# Consume SELECT statement.
	consumeSelect: () ->
		r = {}
		
		# Consume 'SELECT' token.
		r.token = @assertNextToken('SELECT').value
		
		# We must read a field list.
		r.fields = @consumeFieldList()
		
		# FROM is a must.
		@assertNextToken('FROM')
		r.from = @assertNextToken('IDENTIFIER').value
		
		# WHERE is optional.
		r.where = @consumeWhere() if @peekNextToken().token == 'WHERE'
			
		# ORDER BY is optional.
		r.orderBy = @consumeOrderBy() if @peekNextToken().token == 'ORDER'
			
		# LIMIT is optional.
		r.limit = @consumeLimit() if @peekNextToken().token == 'LIMIT'
			
		# SKIP is optional.
		r.skip = @consumeSkip() if @peekNextToken().token == 'SKIP'
		
		# All done.
		return r
	
	# Consume LIMIT clause.
	consumeLimit: () ->
		# Consume 'LIMIT' tokne.
		@assertNextToken('LIMIT')
		
		# Read the number of rows.
		return @assertNextToken('INTEGER').value * 1
		
	# Consume SKIP clause.
	consumeSkip: () ->
		# Consume 'SKIP' token.
		@assertNextToken('SKIP')
		
		# Read the number of rows.
		return @assertNextToken('INTEGER').value * 1
	
	# Consume WHERE clause.
	consumeWhere: () ->
		# Consume 'WHERE' token.
		@assertNextToken('WHERE')
		
		# Consume expression.
		return @consumeExpression()
	
	# Consume ORDER BY clause.
	consumeOrderBy: () ->
		# Consume 'ORDER BY' tokens.
		@assertNextToken('ORDER')
		@assertNextToken('BY')
		
		# Consume fields.
		return @consumeOrderByList()
	
	# Return an **Expression**.
	consumeExpression: () ->
		return new Expression(@consumeAnd())
		
	# @return AndExpression
	consumeAnd: () ->
		ex = new AndExpression(@consumeOr())
		if @peekNextToken().token == 'AND'
			ex.addRight(@assertNextToken('AND'), @consumeExpression())
		return ex
		
	# @return OrExpression
	consumeOr: () ->
		ex = new OrExpression(@consumeComparison())
		if @peekNextToken().token == 'OR'
			ex.addRight(@assertNextToken('OR'), @consumeExpression())
		return ex
		
	# @return ComparisonExpression
	consumeComparison: () ->
		r = new ComparisonExpression(@consumeAdd())
		
		direction = {
			'=': () =>
				@assertNextToken('=')
			'>': () =>
				@assertNextToken('>')
			'<': () =>
				@assertNextToken('<')
			'>=': () =>
				@assertNextToken('>=')
			'<=': () =>
				@assertNextToken('<=')
			'!=': () =>
				@assertNextToken('!=')
			'LIKE': () =>
				@assertNextToken('LIKE')
		}
		if direction[@peekNextToken().token]
			r.addRight(@branch(direction), @consumeSingle())
		
		return r
		
	# @return AddExpression
	consumeAdd: () ->
		ex = new AddExpression(@consumeSingle())
		if @peekNextToken().token == '+'
			ex.addRight(@assertNextToken('+'), @consumeExpression())
		return ex
	
	consumeFieldList: () ->
		r = []
		
		# we must have at least one field
		r.push(@consumeField())
		
		# are their more fields?
		while @peekNextToken().token == ','
			# consume ','
			@assertNextToken(',')
			
			r.push(@consumeField())
		
		return r
	
	consumeField: () ->
		# consume a single field
		return @branch({
			'*': () =>
				@nextToken().value
			'IDENTIFIER': () =>
				@nextToken().value
		})
	
	consumeOrderByList: () ->
		r = []
		
		# we must have at least one field
		r.push(@consumeOrderByField())
		
		# are their more fields?
		while @peekNextToken().token == ','
			# consume ','
			@assertNextToken(',')
			
			r.push(@consumeOrderByField())
		
		return r
	
	# @return OrderByField
	consumeOrderByField: () ->
		# consume a single field
		r = new OrderByField(@assertNextToken('IDENTIFIER'))
		
		# specify an order?
		if @peekNextToken().token == 'ASC' or @peekNextToken().token == 'DESC'
			r.order = @nextToken().value
		
		return r
	
	# @return SingleExpression
	consumeSingle: (peek = false) ->
		@action = @nextToken
		@action = @peekNextToken if peek
		
		# consume a single value
		return new SingleExpression(@branch({
			'IDENTIFIER': () =>
				@action()
			'INTEGER': () =>
				@action()
			'STRING_SINGLE': () =>
				@action()
			'STRING_DOUBLE': () =>
				@action()
		}))
		
class Mql

	processSelect: (tree) ->
		translator = new MqlTranslator()
		
		# filter fields
		where = null
		if tree.where
			where = translator.translateMql(tree.where, 'string')
		
		# select fields
		fields = null
		if tree.fields.length > 1 or tree.fields[0] != '*'
			fields = "{"
			for key, field of tree.fields
				fields += ',' if key > 0
				fields += field + ":1"
			fields += "}"
		
		findMethod = 'find'
		if tree.limit == 1
			findMethod = 'findOne'
		
		# convert the tree into a MongoDB call
		mql = ''
		if fields == null and where == null
			mql = 'db.' + tree.from + '.' + findMethod + '()'
		else if fields != null and where == null
			mql = 'db.' + tree.from + '.' + findMethod + '({}, ' + fields + ')'
		else if fields == null and where != null
			mql = 'db.' + tree.from + '.' + findMethod + '(' + where + ')'
		else
			mql = 'db.' + tree.from + '.' + findMethod + '(' + where + ', ' + fields + ')'
			
		# sort
		if tree.orderBy
			mql += ".sort({"
			for key, value of tree.orderBy
				mql += ',' if key > 0
				mql += value.field + ":"
				
				if value.order == 'DESC'
					mql += "-1"
				else
					mql += "1"
				
			mql += "})"
		
		# limits
		if tree.limit and tree.limit != 1
			mql += ".limit(" + tree.limit + ")"
		if tree.skip
			mql += ".skip(" + tree.skip + ")"
		
		return mql
		
	processDelete: (tree) ->
		translator = new MqlTranslator()
		
		# filter fields
		where = null
		if tree.where
			where = translator.translateMql(tree.where, 'string', 'where')
			
		mql = "db." + tree.from + ".remove("
		mql += where if where
		mql += ")"
		return mql
		
	processUpdate: (tree) ->
		translator = new MqlTranslator()
		
		# filter fields
		where = '{}'
		if tree.where
			where = translator.translateMql(tree.where, 'string', 'where')
		
		mql = "db." + tree.from + ".update(" + where + ", "
		mql += translator.translateMql(tree.set, 'string', 'set')
		mql += ", false, true)"
		return mql
		
	processCreateTable: (tree) ->
		return 'db.createCollection("' + tree.tableName + '")'

	processSql: (sql) ->
		lexer = new MqlLexer(sql)
		parser = new MqlParser(lexer)
		tree = parser.consumeSql()
		
		if tree.token == 'SELECT'
			return @processSelect(tree)
		if tree.token == 'DELETE'
			return @processDelete(tree)
		if tree.token == 'UPDATE'
			return @processUpdate(tree)
		if tree.token == 'CREATE TABLE'
			return @processCreateTable(tree)
			
		throw new Error("Can't understand statement " + tree.token)

# If this is run from the command line execute the parser now.
if process.argv[2]
	mql = new Mql()
	sql = process.argv[2]
	console.log(mql.processSql(sql))

# Export module.
module.exports = {
	Mql: Mql
}
